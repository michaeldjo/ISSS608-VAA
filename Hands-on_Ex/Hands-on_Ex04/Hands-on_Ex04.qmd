---
title: "Hands-on Exercise 4: Fundamentals of Visual Analytics"
author: "Michael Djohan"
date: 02 February 2023
date-modified: "`r Sys.Date()`"
fontsize: smaller
execute: 
  echo: true
  eval: true
  warning: false
format: html
editor: visual
---

## 1. Getting Started

### Install and launching R packages.

The code chunk below uses p_load() of pacman package to check if packages are installed in the computer. If they are, then they will be launched into R. The R packages installed are:

-   [**ggstatsplot**](https://indrajeetpatil.github.io/ggstatsplot/) is an extension of [**ggplot2**](https://ggplot2.tidyverse.org/) package for creating graphics with details from statistical tests included in the information-rich plots themselves.

```{r}
pacman::p_load(ggstatsplot, tidyverse)
```

### Importing the data

```{r}
#| output: false
exam_data <- read_csv("data/Exam_data.csv")
```

## 2. Visual Statistical Analysis

### 2.1 One-sample test using `gghistostats` for

```{r}
set.seed(1234)

gghistostats(
  data = exam_data,
  x = ENGLISH,
  type = "bayes",
  test.value = 60,
  xlab = "English scores"
)
```

Default information: - statistical details - Bayes Factor - sample sizes - distribution summary

A Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.

### 2.2 Two-sample mean test using `ggbetweenstats`

```{r}
ggbetweenstats(
  data = exam_data,
  x = GENDER,
  y = MATHS,
  type = "np",
  messages = FALSE
)
```

Default information: - statistical details - Bayes Factor - sample sizes - distribution summary

### 2.3 Oneway ANOVA Test using `ggbetweenstats`

```{r}
ggbetweenstats(
  data = exam_data, 
  x = RACE, 
  y = ENGLISH, 
  type = "p", 
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE,
  #"ns" for only non-significant, "s" for only significant, "all" for everything
  pairwise.display = "s",      
  p.adjust.method = "fdr", 
  messages = FALSE 
  )
```

### 2.4 Significant Test of Correlation using `ggscatterstats`

```{r}
ggscatterstats(
  data = exam_data,
  x = MATHS,
  y = ENGLISH,
  marginal = FALSE
)
```

### 2.5 Significant Test of Association (Dependence) using `ggbarstats`

```{r}
#Binning Maths scores to 4-class variable
exam1 <- exam_data |> 
  mutate(MATHS_bins =
           cut(MATHS, 
               breaks = c(0, 60, 75, 85, 100)))
```

```{r}
ggbarstats(
  data = exam1,
  x = MATHS_bins,
  y = GENDER
)
```

## 3. Visualising Models

### 3.1 Preparation

```{r}
pacman::p_load(readxl, performance, parameters, see)
```

```{r}
car_resale <- read_xls("data/ToyotaCorolla.xls", 
                       "data")
```

### 3.2 Multiple Regression Model using `lm()`

Calibrate a multiple linear regression model by using lm() of Base Stats of R.

```{r}
model <- lm(Price ~ Age_08_04 + Mfg_Year + KM +
              Weight + Guarantee_Period, data = car_resale)
model
```

### 3.3 Checking for multicollinearity using `check_collinearity()`

```{r}
check_collinearity(model)
```

```{r}
#plot the collinearity
plot(check_collinearity(model))
```

Age_08_04 and Mfg_Year are highly correlated. Remove Mfg_Year

### 3.4 Checking for normality assumption using `check_normality()`

```{r}
#Remove Mfg_Year from model
model1 <- lm(Price ~ Age_08_04 + KM + 
              Weight + Guarantee_Period, data = car_resale)
```

```{r}
check_n <- check_normality(model1)
plot(check_n)
```

The analytical histogram above is specially designed for normality assumption test. When the residual histogram (in cyan colour) is not closed to the theoretical histogram (i.e in green), then we will reject the Null hypothesis and infer that the model residual failed to conform to normality assumption.

### 3.5 Checking for homogeneity of variances using `check_heteroscedasticity()`

```{r}
check_h <- check_heteroscedasticity(model1)
plot(check_h)
```

The analytical scatter plot is used to perform homogeneity of Variance assumption test. A constant variance distribution should be flat and horizontal and the data points should be scattered around the fit line. The chart above shows clear sign of heteroscedasticity.

### 3.6 Complete check using `check_model()`

```{r}
#| fig-height: 15
#| fig-width: 12.5
check_model(model1)
```

### 3.7 Visualising Regression Parameters

Using `plot()` and `parameters()`

```{r}
plot(parameters(model1))
```

Using [*ggcoefstats()*](https://indrajeetpatil.github.io/ggstatsplot/reference/ggcoefstats.html) of ggstatsplot package

```{r}
ggcoefstats(model1, 
            output = "plot")
```

## 4. Visualising Uncertainty

### 4.1 Preparation

```{r}
pacman::p_load(tidyverse, plotly, crosstalk, DT, ggdist, gganimate)
```

### 4.2 Visualizing uncertainty of point estimates using `ggplot2`

-   A point estimate is a single number, such as a mean.
-   Uncertainty is expressed as standard error, confidence interval, or credible interval
-   Don't confuse the uncertainty of a point estimate with the variation in the sample

```{r}
#group by RACE and calculate mean, sd, and se of MATHS score
my_sum <- exam_data |> 
  group_by(RACE) |> 
  summarize(
    n = n(),
    mean = mean(MATHS),
    sd = sd(MATHS)) |>
  mutate(se = sd/sqrt(n-1))
head(my_sum)
```

showing the tibble in html format

```{r}
knitr::kable(head(my_sum), format = 'html')
```

Using `ggplot2` to reveal the standard error of mean maths score by race
```{r}
ggplot(my_sum) +
  
  geom_errorbar(
    aes(x = RACE,
        ymin = mean - se,
        ymax = mean + se),
    width = 0.2,
    colour = "black",
    alpha = 0.9,
    linewidth = 0.5) +
  
  geom_point(
    aes(x = RACE,
        y = mean),
    stat = "identity",
    colour = "red",
    size = 1.5,
    alpha = 1) +
  
  ggtitle("Standard error of mean
          maths score by race")
  
```
Using `ggplot2` to reveal the 95% confidence interval of mean maths score by race
```{r}
my_sum1 <- exam_data |> 
  group_by(RACE) |> 
  summarize(
    n = n(),
    mean = mean(MATHS),
    sd = sd(MATHS)) |>
  mutate(se = sd/sqrt(n-1),
         ci95 = 1.96*se,
         ci99 = 2.58*se)

my_sum1$RACE  <- fct_reorder(my_sum1$RACE, my_sum1$mean, .desc = TRUE)
```


```{r}
ggplot(my_sum1) +
  
  geom_errorbar(
    aes(x = RACE,
        ymin = mean - ci95,
        ymax = mean + ci95),
    width = 0.2,
    colour = "black",
    alpha = 0.9,
    linewidth = 0.5) +
  
  geom_point(
    aes(x = RACE,
        y = mean),
    stat = "identity",
    colour = "red",
    size = 1.5,
    alpha = 1) +
  
  ggtitle("95% confidence interval of mean maths score by race")
  
```
Visualizing the uncertainty of point estimates with interactive error bars
```{r}
d <- highlight_key(my_sum)

p <- ggplot(my_sum1) +
  
  geom_errorbar(
    aes(x = RACE,
        ymin = mean - ci99,
        ymax = mean + ci99),
    width = 0.2,
    colour = "black",
    alpha = 0.9,
    linewidth = 0.5) +
  
  geom_point(
    aes(x = RACE,
        y = mean),
    stat = "identity",
    colour = "red",
    size = 1.5,
    alpha = 1) +
  
  ggtitle("99% confidence interval of mean maths score by race")

gg <- highlight(ggplotly(p),
                "plotly_selected")

dt <- DT::datatable(d, 
                    colnames = c("", "No. of pupils", "Avg Scores", "Std Dev", "Std Error")) |> 
  formatRound(columns = c("mean", "sd", "se"), digits = 2)

crosstalk::bscols(gg,
                  dt,
                  widths = 5)
```

